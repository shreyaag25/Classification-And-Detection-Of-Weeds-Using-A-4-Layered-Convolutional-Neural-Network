{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6e1812",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "# Training and testing folders\n",
    "train_path = cwd+'\\dataset\\Training'\n",
    "valid_path = cwd+'\\dataset\\Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bf1122",
   "metadata": {},
   "outputs": [],
   "source": [
    "broadleaf_dir = train_path +\"\\\\broadleaf\"\n",
    "grass_dir = train_path +\"\\\\grass\"\n",
    "soil_dir = train_path +\"\\\\soil\"\n",
    "soybean_dir =train_path +\"\\\\soybean\"\n",
    "\n",
    "print('total training broadleaf images:', len(os.listdir(broadleaf_dir)))\n",
    "print('total training grass images:', len(os.listdir(grass_dir)))\n",
    "print('total training soil images:', len(os.listdir(soil_dir)))\n",
    "print('total training soybean images:', len(os.listdir(soybean_dir)))\n",
    "\n",
    "broadleaf_files = os.listdir(broadleaf_dir)\n",
    "print(broadleaf_files[:10])\n",
    "\n",
    "grass_files = os.listdir(grass_dir)\n",
    "print(grass_files[:10])\n",
    "\n",
    "soil_files = os.listdir(soil_dir)\n",
    "print(soil_files[:10])\n",
    "\n",
    "soybean_files = os.listdir(soybean_dir)\n",
    "print(soybean_files[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c1468f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "pic_index = 2\n",
    "\n",
    "next_broadleaf = [os.path.join(broadleaf_dir, fname) \n",
    "                for fname in broadleaf_files[pic_index-2:pic_index]]\n",
    "next_grass = [os.path.join(grass_dir, fname) \n",
    "                for fname in grass_files[pic_index-2:pic_index]]\n",
    "next_soil = [os.path.join(soil_dir, fname) \n",
    "                for fname in soil_files[pic_index-2:pic_index]]\n",
    "next_soybean = [os.path.join(soybean_dir, fname) \n",
    "                for fname in soybean_files[pic_index-2:pic_index]]\n",
    "\n",
    "for i, img_path in enumerate(next_broadleaf+next_grass+next_soil+next_soybean):\n",
    "  #print(img_path)\n",
    "  img = mpimg.imread(img_path)\n",
    "  plt.imshow(img)\n",
    "  plt.axis('Off')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eea947e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras_preprocessing\n",
    "from keras_preprocessing import image\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "TRAINING_DIR = train_path\n",
    "training_datagen = ImageDataGenerator(\n",
    "      rescale = 1./255,\n",
    "\t  rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "VALIDATION_DIR = valid_path\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_generator = training_datagen.flow_from_directory(\n",
    "\tTRAINING_DIR,\n",
    "\ttarget_size=(200,200),\n",
    "\tclass_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "\tVALIDATION_DIR,\n",
    "\ttarget_size=(200,200),\n",
    "\tclass_mode='categorical'\n",
    ")\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image 200x200 with 3 bytes color\n",
    "    # This is the first convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(200, 200, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The third convolution\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fourth convolution\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit_generator(train_generator, epochs=25, validation_data = validation_generator, verbose = 1)\n",
    "\n",
    "model.save(\"rps.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be2f6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "acc_percentage = (sum(acc)/len(acc))*100\n",
    "print(\"Training Accuracy percentage:\", acc_percentage)\n",
    "\n",
    "accpercentage = (sum(val_acc)/len(val_acc))*100\n",
    "print(\"Validation Accuracy percentage:\", accpercentage)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b9f4eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Resize all the images to this\n",
    "IMAGE_SIZE = [200, 200]\n",
    "\n",
    "# Create an instance of ImageDataGenerator\n",
    "gen = ImageDataGenerator(\n",
    "  rotation_range=20,\n",
    "  width_shift_range=0.1,\n",
    "  height_shift_range=0.1,\n",
    "  shear_range=0.1,\n",
    "  zoom_range=0.2,\n",
    "  horizontal_flip=True,\n",
    "  vertical_flip=True,\n",
    "  rescale=1./255\n",
    ")\n",
    "\n",
    "# Get label mapping of class and label number\n",
    "test_gen = gen.flow_from_directory(valid_path, target_size=IMAGE_SIZE)\n",
    "print(test_gen.class_indices)\n",
    "labels = [None] * len(test_gen.class_indices)\n",
    "for k, v in test_gen.class_indices.items():\n",
    "  labels[v] = k\n",
    "\n",
    "valid_generator = gen.flow_from_directory(\n",
    "  valid_path,\n",
    "  target_size=IMAGE_SIZE,\n",
    "  shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "# Visualizing predictions\n",
    "result = np.round(model.predict_generator(valid_generator))\n",
    "import random\n",
    "test_files = []\n",
    "actual_res = []\n",
    "test_res = []\n",
    "for i in range(0, 20):\n",
    "  rng = random.randint(0, len(valid_generator.filenames))\n",
    "  test_files.append(valid_path+\"\\\\\" +  valid_generator.filenames[rng])\n",
    "  actual_res.append(valid_generator.filenames[rng].split('/')[0])\n",
    "  test_res.append(labels[np.argmax(result[rng])])\n",
    "    \n",
    "for i in range(0, 20):\n",
    "  img = plt.imread(test_files[i])\n",
    "  plt.imshow(img)\n",
    "  plt.axis('Off')\n",
    "  plt.show()\n",
    "  print(\"Actual class: \" + str(actual_res[i]))\n",
    "  print(\"Predicted class: \" + str(test_res[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafe2cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
